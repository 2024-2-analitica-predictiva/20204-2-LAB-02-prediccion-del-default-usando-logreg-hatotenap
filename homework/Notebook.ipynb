{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de datos:\n",
    "Se realiza la lectura en pandas de los archivos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    \"../files/input/test_data.csv.zip\",\n",
    "    index_col=False,\n",
    "    compression=\"zip\",\n",
    ")\n",
    "train_data = pd.read_csv(\n",
    "    \"../files/input/train_data.csv.zip\",\n",
    "    index_col=False,\n",
    "    compression=\"zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos las columnas 'default payment next month' tanto en los datos de entrenamiento como en los de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Renombre la columna \"default payment next month\" a \"default\".\n",
    "test_data = test_data.rename(columns={'default payment next month': 'default'})\n",
    "train_data = train_data.rename(columns={'default payment next month': 'default'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la columna 'ID' no aporta información útil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Remueva la columna \"ID\".\n",
    "test_data=test_data.drop(columns=['ID'])\n",
    "train_data=train_data.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos las filas donde MARRIAGE y EDUCATION no sea igual a '0' tanto en el conjunto de prueba como en el de entranamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Para train_data\n",
    "train_data = train_data.loc[train_data[\"MARRIAGE\"] != 0]\n",
    "train_data = train_data.loc[train_data[\"EDUCATION\"] != 0]\n",
    "\n",
    "\n",
    "# Para test_data (corregido)\n",
    "test_data = test_data.loc[test_data[\"MARRIAGE\"] != 0]\n",
    "test_data = test_data.loc[test_data[\"EDUCATION\"] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la columna EDUCATION, valores > 4 indican niveles superiores de educación, se agrupa estos valores en la categoría \"others\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION\n",
      "2    9756\n",
      "1    7476\n",
      "3    3396\n",
      "4     325\n",
      "Name: count, dtype: int64\n",
      "EDUCATION\n",
      "2    4268\n",
      "1    3105\n",
      "3    1477\n",
      "4     129\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data['EDUCATION'] = test_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "train_data['EDUCATION'] = train_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "print(train_data[\"EDUCATION\"].value_counts())\n",
    "print(test_data[\"EDUCATION\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos conjuntos de datos de entrenamiento y prueba \n",
    "tanto para los datos de entrenamiento y prueba, en las características o x_train y x_test se elimina la columna \"default\" ya que esta es el target o y_train y y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data.drop(columns=\"default\")\n",
    "y_train=train_data[\"default\"]\n",
    "\n",
    "\n",
    "x_test=test_data.drop(columns=\"default\")\n",
    "y_test=test_data[\"default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un preprocesamiento de los datos, definimos variables categóricas y variables numéricas\n",
    "\n",
    "para las variables categóricas aplicamos el OneHotEnconder transformandolas en un vector binario, se normaliza las variables para que no hayan tendencias significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "\n",
    "categorical_columns = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "numerical_columns = [col for col in x_train.columns if col not in categorical_columns]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_columns),\n",
    "    (MinMaxScaler(), numerical_columns),\n",
    "    remainder='passthrough'  # conservan cambios en columnas diferentes a las categóricas \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Creación del pipeline*\n",
    "- Se crea la \"receta para entrenar el modelo en este caso una regresión logística\n",
    "- Se aplica las transformaciones definidas en el preprocesador\n",
    "- selecciona las 'k' carácteristicas más relevantes para predecir la variable objetivo 'default' ( k será definida más adelante)\n",
    "- Reproducibilidad fijando una semilla aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    ('feature_selection', SelectKBest(score_func = f_classif)),\n",
    "    ('classifier', LogisticRegression(random_state = 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optimización del pipeline*\n",
    "\n",
    "Especificamos los hiperparámetros y sus posibles valores:\n",
    "\n",
    "- Características 1 a 10\n",
    "- Regresión logística\n",
    "- Penalización \n",
    "- Tipo de Algoritmo\n",
    "- Número máximo de iteraciones\n",
    "\n",
    "*Validación cruzada*\n",
    "- Dividel los datos en 10 subcojuntos: 9 para entrenar y 1 para validad, rotando hasta usar todos como validación.\n",
    "- Usa precisión balancead que es adecuada para datos desbalanceados\n",
    "- Usar los núcleso de la CPU acelerando la búsqueda. para mi caso mi pc tiene 14 núcleos y 20 hilos (threads)\n",
    "- Una vez encontrados los mejores hiperparámetros, se ajusta el pipeline completo con estos valores usando todo el conjunto de entrenamiento (refit=True)\n",
    "- Entrenamos el modelo usando el conjunto de entreanamiento x_train y_train y realiza la búsqueda de hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'classifier__C': 0.1, 'classifier__max_iter': 100, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'feature_selection__k': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid={\n",
    "        'feature_selection__k': range(1, 11),\n",
    "        'classifier__C': [0.1],\n",
    "        'classifier__penalty': ['l1'],\n",
    "        'classifier__solver': ['liblinear'],\n",
    "        'classifier__max_iter': [100],\n",
    "    },\n",
    "    cv=10,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ").fit(x_train, y_train)\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {model.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Guardamos el modelo hecho*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en '../files/models/model.pkl.gz'\n"
     ]
    }
   ],
   "source": [
    "# Importar las librerías necesarias\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "models_dir = '../files/models'\n",
    "os.makedirs(models_dir, exist_ok = True)\n",
    "\n",
    "# Definir la ruta donde se guardará el modelo\n",
    "model_path = \"../files/models/model.pkl.gz\"\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo\n",
    "with gzip.open(model_path, \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(f\"Modelo guardado en '{model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Métricas de evaluación y matrices de confusión*\n",
    "\n",
    "Este código calcula métricas de evaluación y matrices de confusión para el modelo entrenado y guarda los resultados en un archivo JSON línea por línea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definimos la función que calcula las métricas  \"calculate_metrics\" la cual comprar la etiquetas reales  y_true vs y_pred, especificando con dataset_type si las métricas calculadas pertenencen al conjunto de entrenamiento o prueba\n",
    "\n",
    "Cada métrica se calcula utilizando las funciones de sklearn.metrics : Precisión, Precisión balanceada, recall,F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función para calcular las matrices de confusión y así comprender el rendimiento del modelo en cada clase.\n",
    "La idea es calcular los verdaderos negativos, Falsos positivos, Falsos negativos, verdaderos positivos\n",
    "Utiliza el modelo entrenado para predecir las etiquetas (y_train_pred, y_test_pred) en los conjuntos de entrenamiento x_train y prueba x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de definidas las dos funciones auxiliares procedemos a hacer las respectivas predicciones y a calcular las metricas y las matrices de confusión para cada dataset para guardarlos como .json en la carpeta output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas y matrices de confusión guardadas exitosamente.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# Función para calcular métricas generales\n",
    "def calculate_metrics(y_true, y_pred, dataset_type):\n",
    "    return {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": dataset_type,\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "# Función para formatear matrices de confusión\n",
    "def format_confusion_matrix(cm, dataset_type):\n",
    "    return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": dataset_type,\n",
    "        \"true_0\": {\"predicted_0\": int(cm[0, 0]), \"predicted_1\": int(cm[0, 1])},\n",
    "        \"true_1\": {\"predicted_0\": int(cm[1, 0]), \"predicted_1\": int(cm[1, 1])},\n",
    "    }\n",
    "\n",
    "# Hacer predicciones\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Calcular métricas y matrices de confusión\n",
    "entries = [\n",
    "    calculate_metrics(y_train, y_train_pred, \"train\"),\n",
    "    calculate_metrics(y_test, y_test_pred, \"test\"),\n",
    "    format_confusion_matrix(confusion_matrix(y_train, y_train_pred), \"train\"),\n",
    "    format_confusion_matrix(confusion_matrix(y_test, y_test_pred), \"test\"),\n",
    "]\n",
    "\n",
    "# Crear carpeta de salida y guardar métricas línea por línea\n",
    "os.makedirs(\"../files/output\", exist_ok=True)\n",
    "with open(\"../files/output/metrics.json\", \"w\") as f:\n",
    "    for entry in entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"Métricas y matrices de confusión guardadas exitosamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
